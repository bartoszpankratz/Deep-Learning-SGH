{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn how to work with **Recurrent Neural Networks** we will build the ([<b>Character-Level Language Model</b>](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)). Our goal is to train the conditional probability model, which will predict the next character in the sequence given the previous elements: \n",
    "\n",
    "$$P(c_k|\\{c_1,c_2,\\dots,c_{k-1}\\})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work on the dataset containing all William Shakespeare playwrights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://upload.wikimedia.org/wikipedia/commons/a/a2/Shakespeare.jpg)](https://en.wikipedia.org/wiki/William_Shakespeare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Tomorrow, and tomorrow, and tomorrow,\n",
    "Creeps in this petty pace from day to day,\n",
    "To the last syllable of recorded time;\n",
    "And all our yesterdays have lighted fools\n",
    "The way to dusty death. Out, out, brief candle!\n",
    "Life's but a walking shadow, a poor player\n",
    "That struts and frets his hour upon the stage,\n",
    "And then is heard no more. It is a tale\n",
    "Told by an idiot, full of sound and fury,\n",
    "Signifying nothing.\n",
    "\n",
    "    Macbeth, Act V, scene v."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a model, that generates a new playwright (or at least its snippet) based on previously generated letters. But before we start implementing code, let us talk about the theory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the neural network architectures we previously discussed, RNN networks are directed cyclic graphs. It means that the data could flow in the network not only in one direction (forward) but also can be propagated through neurons in the same layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://karpathy.github.io/assets/rnn/diags.jpeg)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, RNNs are especially useful for building **n-gram** language models: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://karpathy.github.io/assets/rnn/charseq.jpeg)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Long short-term memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "The biggest issue with a basic form of Recurrent Neural Network architecture is the problem of vanishing information, which is especially visible in the long sequences, where meaningful pieces of information are often separated by long chains of less impactful data. Basic RNNs can learn the relationships easily only when intertwined elements are close in the chain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-shorttermdepdencies.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "But when the gap between them is large, then the relation can get lost in the noise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid that we must redefine the model. A good solution is to use **Long-Short Term Memory** (LSTM) layers, which can control the flow of information and filter the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of LSTMs and their [modifications](https://en.wikipedia.org/wiki/Long_short-term_memory) one might use other kinds of RNN layers, e.g.  <b>Gated Recurrent Unit<b> (GRU) networks:\n",
    "    \n",
    "[![](https://upload.wikimedia.org/wikipedia/commons/5/5f/Gated_Recurrent_Unit.svg)](https://en.wikipedia.org/wiki/Gated_recurrent_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or more case-specific models, e.g. layers designed specifically for modelling [time-series.](https://github.com/sdobber/FluxArchitectures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using Flux\n",
    "using Flux: onehot, onehotbatch, argmax, chunk, batchseq, crossentropy\n",
    "using StatsBase: wsample\n",
    "using Base.Iterators: partition\n",
    "using BSON\n",
    "using JLD2\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining on GPU\n"
     ]
    }
   ],
   "source": [
    " if use_cuda && CUDA.functional()\n",
    "    device = gpu\n",
    "    @info \"Training on GPU\"\n",
    "else\n",
    "    device = cpu\n",
    "    @info \"Training on CPU\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we will collect and prepare the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isfile(\"shakespeare.txt\") ||\n",
    "        download(\"https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\",\"shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_': ASCII/Unicode U+005F (category Pc: Punctuation, connector)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = collect(read(\"shakespeare.txt\",String));\n",
    "alphabet = [unique(text)..., '_'];\n",
    "stop = '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = length(alphabet);\n",
    "seqlen = 100;\n",
    "batch_size = 64;\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split text into parts of size batch_size:\n",
    "X = [collect(t) for t in chunk(text, batch_size)]\n",
    "Y = [collect(t) for t in chunk(text[2:end], batch_size)]\n",
    "#match corresponding elements of each chunk from previous step:\n",
    "X = partition(batchseq(X, stop), seqlen)\n",
    "Y = partition(batchseq(Y, stop), seqlen)\n",
    "#collect batches of data:\n",
    "X = [Flux.onehotbatch.(b, (alphabet,)) for b in X]\n",
    "Y = [Flux.onehotbatch.(b, (alphabet,)) for b in Y];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = shuffle(1:length(X))\n",
    "split = floor(Int, 0.95 * length(X))\n",
    "\n",
    "trainX, trainY = X[perm[1:split]], Y[perm[1:split]] |> device\n",
    "testX,  testY =  X[perm[(split+1):end]], Y[perm[(split+1):end]] |> device;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 2 methods)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "    Embedding(N, 256),\n",
    "    LSTM(256, 1024),\n",
    "    Dense(1024, N),\n",
    "    softmax) |> device\n",
    "\n",
    "function loss(model, xs, ys, ϵ = 1.0f-8)\n",
    "    Flux.reset!(m)\n",
    "    l = sum(crossentropy.(broadcast(x -> model(x) .+ ϵ, xs), ys))\n",
    "    return l\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31.927109 seconds (46.40 M allocations: 1.903 GiB, 1.87% gc time, 75.08% compilation time: 1% of which was recompilation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06648952f0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(loss.(Ref(m), testX, testY)) / (batch_size * seqlen * length(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(0.001)\n",
    "opt_state = Flux.setup(opt, m);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sample(m, alphabet, len)\n",
    "    model = cpu(m)\n",
    "    Flux.reset!(model)\n",
    "    buf = IOBuffer()\n",
    "    c = rand(alphabet)\n",
    "    for i = 1:len\n",
    "        write(buf, c)\n",
    "        c = wsample(alphabet, model(onehot(c, alphabet)))\n",
    "      end\n",
    "    return String(take!(buf))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"yfr\\nj'rfjjTg-tFOh_L3KJg[Xk3M_jIijag_tUM]jtvbBc?]bG\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(m, alphabet, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mBeginning training loop...\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 1\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mKlh]Tk],.ObkgAV cgs,\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mRV\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39myh&eu!d&FVJWazjp_Xt\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mXyxDVdC-.\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m!WZ]f,IMc zWE-&uudwT$L[[LRHBe$nW_k-$OeJo$MJRbv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.036813036f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mNew best result: 0.036813036\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 2\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mXnnnnnnnnnnn nnnngngngd ncken ne nn  gns wne in n knos; no fu de me nue.\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mge enin be itid no dfd me \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.034421377f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mNew best result: 0.034421377\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 3\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m_!QCxJJpJQ[M&AxR;VKG3C]AqcGE3Mf_V;eeeeeeeieeeeeeeeeeeeeeeeeeeeeeeieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.03215535f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mNew best result: 0.03215535\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 4\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m]SJgB&Cq?FD&RL]LxRmTVqQccLg]t.t you sle dist 's nihon Puffut thy kes us WARANIUS:\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mWick oy deathy mot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.03226347f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 5\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mc.\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mr th th me, the sfart.\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mROTOBENZO:\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mWhich: ye, shall wn liffepring consse gersigngg.\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mUS:\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mI withee,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.030669462f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mNew best result: 0.030669462\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 6\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mccr, oas! poonle we impry-wason alosampon Bil swer;\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mHearn, it do lord mier, my rorane; or onf's rest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.03070914f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 7\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mQCxFDwNwQLqGcoll, sp.\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mFORIO:\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mI ver ! rindss Ant they lich cullly u certlan,\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mWhrLARnge,\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mCoart me ton\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.030402586f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mNew best result: 0.030402586\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 8\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mH,'t es bese, he jounansose ok\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mA no; God! which h me, lear be vart peice of hey handeediAft, I\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mse he\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.029987825f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mNew best result: 0.029987825\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 9\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m'rrst the defUS:\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mO, and HeC nevery I had Speome the thy may to he lour at of hight om! mades it in a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.03059442f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 10\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m.\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mHow good is thand, be to you her, my chose thou sice, and w nigh'd as operched I at shou ofna par\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.030644182f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 11\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mhaiscas can is I with say, disI knone a a till IOLANUSIUS:\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mGrodshe hadfights.\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mSROSIUMNIN NARESBO:\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.0299684f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mNew best result: 0.0299684\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 12\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mR,\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mn's les, sing thus,\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mAt ey, an will e'ee thou in wild; the: mothe prove ow\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39me\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mMot't the do the dius\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.030566663f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 13\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLE,, b gue blow be the fe, led me ? 'S FRILINs\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mI shall five to kne trutbednglak you, sight the feith\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.031807307f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 14\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m]K\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mLoetehere hearm,\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mThere andeed:\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mI in thee ifINUNIUS:\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mGood doughereyal theieapiet, and inideeeeineo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.030466527f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 15\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mBy sure sir, them\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mth;\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mBIRONY:\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mO, lder wao had supon of man shall then pdiust menceize not dry sfis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.03131429f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 16\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mKcouroesperinessiterive.\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mYet,\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mHad noteadld bid, to the good beone.\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mPCINIUS:\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mWhiceral dayes;\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mA.\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mPoe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls = 0.030072836f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39m -> We're calling this converged.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Main In[14]:20\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@info(\"Beginning training loop...\")\n",
    "best_ls = Inf\n",
    "last_improvement = 0\n",
    "for epoch = 1:epochs\n",
    "    @info \"Epoch: $epoch\"\n",
    "    global best_ls, last_improvement\n",
    "    @info sample(m, alphabet, 100)\n",
    "    Flux.train!(loss, m, zip(trainX, trainY), opt_state)\n",
    "    ls = sum(loss.(Ref(m), testX, testY)) / (batch_size * seqlen * length(testX))\n",
    "    @show ls\n",
    "    if ls <= best_ls      \n",
    "        @info \"New best result: $ls\"\n",
    "        char_model = cpu(Flux.state(m)) \n",
    "        BSON.@save \"char_model.bson\" char_model\n",
    "        jldsave(\"char_model.jld2\"; char_model)\n",
    "        best_ls = ls\n",
    "        last_improvement = epoch\n",
    "    end\n",
    "    if epoch - last_improvement >= 5\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Encountered tied destination parameters with untied and mismatched sources.",
     "output_type": "error",
     "traceback": [
      "Encountered tied destination parameters with untied and mismatched sources.",
      "",
      "Stacktrace:",
      " [1] error(s::String)",
      "   @ Base .\\error.jl:35",
      " [2] _tie_check",
      "   @ C:\\Users\\barto\\.julia\\packages\\Flux\\htpCe\\src\\loading.jl:29 [inlined]",
      " [3] loadmodel!(dst::Tuple{Matrix{Float32}, Matrix{Float32}}, src::Tuple{Matrix{Float32}, Matrix{Float32}}; filter::Function, cache::IdSet{Any})",
      "   @ Flux C:\\Users\\barto\\.julia\\packages\\Flux\\htpCe\\src\\loading.jl:100",
      " [4] loadmodel!(dst::Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, src::@NamedTuple{cell::@NamedTuple{Wi::Matrix{Float32}, Wh::Matrix{Float32}, b::Vector{Float32}, state0::Tuple{Matrix{Float32}, Matrix{Float32}}}, state::Tuple{Matrix{Float32}, Matrix{Float32}}}; filter::Function, cache::IdSet{Any})",
      "   @ Flux C:\\Users\\barto\\.julia\\packages\\Flux\\htpCe\\src\\loading.jl:105",
      " [5] loadmodel!(dst::Tuple{Embedding{Matrix{Float32}}, Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}, src::Tuple{@NamedTuple{weight::Matrix{Float32}}, @NamedTuple{cell::@NamedTuple{Wi::Matrix{Float32}, Wh::Matrix{Float32}, b::Vector{Float32}, state0::Tuple{Matrix{Float32}, Matrix{Float32}}}, state::Tuple{Matrix{Float32}, Matrix{Float32}}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}, σ::Tuple{}}, Tuple{}}; filter::Function, cache::IdSet{Any})",
      "   @ Flux C:\\Users\\barto\\.julia\\packages\\Flux\\htpCe\\src\\loading.jl:105",
      " [6] loadmodel!(dst::Chain{Tuple{Embedding{Matrix{Float32}}, Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}}, src::@NamedTuple{layers::Tuple{@NamedTuple{weight::Matrix{Float32}}, @NamedTuple{cell::@NamedTuple{Wi::Matrix{Float32}, Wh::Matrix{Float32}, b::Vector{Float32}, state0::Tuple{Matrix{Float32}, Matrix{Float32}}}, state::Tuple{Matrix{Float32}, Matrix{Float32}}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}, σ::Tuple{}}, Tuple{}}}; filter::Function, cache::IdSet{Any})",
      "   @ Flux C:\\Users\\barto\\.julia\\packages\\Flux\\htpCe\\src\\loading.jl:105",
      " [7] loadmodel!(dst::Chain{Tuple{Embedding{Matrix{Float32}}, Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}}, src::@NamedTuple{layers::Tuple{@NamedTuple{weight::Matrix{Float32}}, @NamedTuple{cell::@NamedTuple{Wi::Matrix{Float32}, Wh::Matrix{Float32}, b::Vector{Float32}, state0::Tuple{Matrix{Float32}, Matrix{Float32}}}, state::Tuple{Matrix{Float32}, Matrix{Float32}}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}, σ::Tuple{}}, Tuple{}}})",
      "   @ Flux C:\\Users\\barto\\.julia\\packages\\Flux\\htpCe\\src\\loading.jl:90",
      " [8] top-level scope",
      "   @ In[48]:13"
     ]
    }
   ],
   "source": [
    "m = Chain(\n",
    "    Embedding(N, 256),\n",
    "    LSTM(256, 1024),\n",
    "    Dense(1024, N),\n",
    "    softmax) \n",
    "\n",
    "#BSON.@load \"char_model.bson\" char_model\n",
    "\n",
    "#Flux.loadmodel!(m, char_model)\n",
    "\n",
    "ps = JLD2.load(\"char_model.jld2\", \"char_model\")\n",
    "\n",
    "Flux.loadmodel!(m, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access Tuple{@NamedTuple{weight::Matrix{Float32}}, @NamedTuple{cell::@NamedTuple{Wi::Matrix{Float32}, Wh::Matrix{Float32}, b::Vector{Float32}, state0::Tuple{Matrix{Float32}, Matrix{Float32}}}, state::Tuple{Matrix{Float32}, Matrix{Float32}}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}, σ::Tuple{}}, Tuple{}} at index [5]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access Tuple{@NamedTuple{weight::Matrix{Float32}}, @NamedTuple{cell::@NamedTuple{Wi::Matrix{Float32}, Wh::Matrix{Float32}, b::Vector{Float32}, state0::Tuple{Matrix{Float32}, Matrix{Float32}}}, state::Tuple{Matrix{Float32}, Matrix{Float32}}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}, σ::Tuple{}}, Tuple{}} at index [5]",
      "",
      "Stacktrace:",
      " [1] getindex(t::Tuple, i::Int64)",
      "   @ Base .\\tuple.jl:31",
      " [2] top-level scope",
      "   @ In[43]:1"
     ]
    }
   ],
   "source": [
    "ps.layers[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KmYpDPRrVG]iXAF,IXv$Rg\n",
      "yIDk3]bZe,Yn!3ieksMfb?XKA$fQK''W,fAufDu?\n",
      "crqK l\n",
      "v&xbWqajT]E.u;?wKCFA-X]AySqbg"
     ]
    }
   ],
   "source": [
    "print(sample(m, alphabet, 100))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.11.0",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
